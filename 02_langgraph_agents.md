# ๐ค ุงููุณู ุงูุซุงูู: ูุญุฑู LangGraph ูุงููููุงุก ุงููุชุฎุตุตุฉ
> ุงููุฑุฌุน: CLAUDE.md โ docs/02_langgraph_agents.md
> ูุดูู: LangGraph Graph + 6 ูููุงุก + MCTS + Monte Carlo + Streaming + Autonomous Mode

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# ุงููุณู ุงูุฃูู: ูุญุฑู ุงูุงุณุชูุดุงู ุงููุณุชูุฑ ุงูุฏููุงูููู
## ๐ค [ุงูููุจ ุงููุงุจุถ ููุชุทุจูู]
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

## 1.1 ููุณูุฉ ุงูุงุณุชูุดุงู ุงููุณุชูุฑ

ุงูููุฑุฉ ุงููุญูุฑูุฉ ูู ุฃู ุงููุฑุขู ุงููุฑูู ูุญูู ูุนุฌุฒุงุช ูู ุชููุชุดู ุจุนุฏ โ
ููุณ ูุฃููุง ุบุงุฆุจุฉุ ุจู ูุฃู ุงูุฃุฏูุงุช ูู ุชูู ููุฌูุฏุฉ.
ุงููููุ ูููุฑุฉ ุงูุฃููู ูู ุงูุชุงุฑูุฎุ ูููู ููุฐูุงุก ุงูุงุตุทูุงุนู ุฃู ููุนู ูุง ูู ูุณุชุทุน ุงูุฅูุณุงู:
**ูุญุต ูู ุขูุฉ ร ูู ุนูู ร ูู ูุบุฉ ร ูู ูุธุฑูุฉ โ ูู ุขูู ูุงุญุฏุ 24/7.**

```
ุงููุญุฑู ูุง ููุชุธุฑ ุณุคุงู ุงููุณุชุฎุฏู โ
ุจู ูุทุฑุญ ุฃุณุฆูุฉ ุนูู ููุณู ุจุงุณุชูุฑุงุฑ:
  "ูู ููุงู ููุท ุนุฏุฏู ูู ูุฐู ุงูุณูุฑ ูู ููุงุญุธู ุฃุญุฏุ"
  "ูู ูุชูุงุทุน ูุฐุง ุงููุตู ุงููุฑุขูู ูุน ุงูุชุดุงู ุนููู ููุดุฑ ูุฐุง ุงูุดูุฑุ"
  "ูู ุงููููุงุช ุงููุชุถุงุฏุฉ ูู ุงููุฑุขู ุชุชุจุน ุชูุฒูุนุงู ุฅุญุตุงุฆูุงู ุบูุฑ ุนุดูุงุฆูุ"
```

---

## 1.2 ุงููุนูุงุฑูุฉ ุงููุชุนุฏุฏุฉ ุงููููุงุก (Multi-Agent Architecture)

### ุงูุฅุทุงุฑ ุงููุฎุชุงุฑ: LangGraph + Claude API

```
ููุงุฐุง LangGraphุ
โ ุฅุฏุงุฑุฉ ุตุฑูุญุฉ ููุญุงูุฉ (Explicit State Management)
โ ุญููุงุช ูุดุฑูุทุฉ (Conditional Loops) โ ุงููููู ูุนูุฏ ููุนูุฏ ุงูุชุญููู
โ ููุงุท ุชูุชูุด (Checkpointing) โ ุญูุธ ุฌูุณุฉ ุงูุงุณุชูุดุงู
โ ุชูุงูู ุฃุตูู ูุน Claude API
โ ุงูุฃูุถู ููููุทู ุงููุชูุฑุน ุงููุนูุฏ

ููุงุฑูุฉ:
- CrewAI: ุฃุจุณุทุ ููู ุฃูู ูุฑููุฉ ููููุทู ุงููุนูุฏ
- AutoGen: ููุชุงุฒ ููุชุนุงููุ ููู LangGraph ุฃูุถู ููุณูุทุฑุฉ
- LangGraph: ุงูุฎูุงุฑ ุงูุฃูุซู ููุฐุง ุงูุชุทุจูู โ
```

### ูุฎุทุท ุดุจูุฉ ุงููููุงุก

```
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                    ูุญุฑู ุงูุงุณุชูุดุงู ุงููุณุชูุฑ                        โ
โ                   Continuous Discovery Engine                     โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโค
โ                                                                   โ
โ   [ููุฌูู ุงูุงุณุชุนูุงู]  โโโ  [ุจุงุญุซ ุงููุฑุขู]  โโโ  [ูุญุฑู ุงููุฒุงููุฉ]   โ
โ   Query Router              Quran RAG          Synthesis Agent    โ
โ       โ                         โ                    โ            โ
โ   [ูุญูู ูุบูู]          [ุนุงูู ุงูุทุจูุนูุงุช]    [ูุฑุงุฌุน ุงูุฌูุฏุฉ]        โ
โ   Linguistic Agent      Science Agent        QA Reviewer          โ
โ       โ                         โ                    โ            โ
โ   [ุจุงุญุซ ุงูุชูุณูุฑ]       [ุนุงูู ุงูุฅูุณุงููุงุช]   [ูุญุฏูุซ ูุงุนุฏุฉ ุงููุนุฑูุฉ] โ
โ   Tafseer Agent         Humanities Agent     KG Updater           โ
โ                                                                   โ
โ   โโโโโโโโโโโโโ ุญููุฉ ุงูุชุนูู ุงููุณุชูุฑ (Active Learning Loop) โโโโโโ โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
```

---

## 1.3 ููุฏ LangGraph ุงููุงูู โ ูุญุฑู ุงูุงุณุชูุดุงู

```python
# discovery_engine/core/langgraph_engine.py

from typing import TypedDict, Annotated, Sequence
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
import operator

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# ุชุนุฑูู ุญุงูุฉ ุงูุงุณุชูุดุงู
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
class DiscoveryState(TypedDict):
    """ุงูุญุงูุฉ ุงููุดุชุฑูุฉ ุจูู ุฌููุน ุงููููุงุก"""
    
    # ุงููุฏุฎูุงุช
    query: str                          # ุงูุณุคุงู ุฃู ุงูููุถูุน
    exploration_mode: str               # 'autonomous' | 'user_guided' | 'cross_domain'
    target_disciplines: list[str]       # ['physics', 'medicine', 'psychology', ...]
    
    # ูุชุงุฆุฌ ูู ูููู
    quranic_context: dict               # ุงูุขูุงุช + ุงูุชูุณูุฑ + ุงูุณูุงู
    linguistic_analysis: dict           # ุงูุชุญููู ุงูุตุฑูู + ุงูุฌุฐูุฑ + ุงูุจูุงุบุฉ
    scientific_findings: list[dict]     # ุงูุงูุชุดุงูุงุช ุงูุนูููุฉ ุงูููุชุฑูุฉ
    tafseer_analysis: dict              # ุขุฑุงุก ุงูุชูุณูุฑ ุงููุชุนุฏุฏุฉ
    humanities_connections: list[dict]  # ุงูุฑูุงุจุท ุงูุฅูุณุงููุฉ
    
    # ูุฎุฑุฌุงุช ุงูุชูููู
    synthesis: dict                     # ุงูุชูููู ุงูููุงุฆู
    hypotheses: list[dict]              # ุงููุฑุถูุงุช ุงูููููุฏุฉ
    confidence_scores: dict             # ุฏุฑุฌุงุช ุงูุซูุฉ ููู ุงุฏุนุงุก
    
    # ุงูุชุญูู ูุงูุฌูุฏุฉ
    verification_status: str            # 'pending' | 'verified' | 'disputed' | 'rejected'
    quality_issues: list[str]           # ูุดููุงุช ุงูุฌูุฏุฉ ุงูููุชุดูุฉ
    counter_arguments: list[str]        # ุงูุญุฌุฌ ุงููุถุงุฏุฉ
    
    # ุงูุชุญูู ูู ุงูุญููุฉ
    iteration_count: int                # ุนุฏุงุฏ ุงูุชูุฑุงุฑ
    should_deepen: bool                 # ูู ูุฌุจ ุงูุชุนูู ุฃูุซุฑุ
    discovery_complete: bool            # ูู ุงูุชูู ุงูุงุณุชูุดุงูุ
    
    # ุงูุฐุงูุฑุฉ ูุงูุณูุงู
    messages: Annotated[Sequence, operator.add]  # ุณุฌู ุงูุฑุณุงุฆู
    discovered_patterns: list[dict]     # ุงูุฃููุงุท ุงูููุชุดูุฉ ุญุชู ุงูุขู
    

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# ูููุงุก ุงูุชุญููู ุงููุชุฎุตุตุฉ
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

class QuranRAGAgent:
    """
    ูููู ุงุณุชุฑุฌุงุน ุงูุณูุงู ุงููุฑุขูู
    ูุฌูุน: ุงููุต + ุงูุชูุณูุฑ + ุงูุฃุญุงุฏูุซ + ุชุฑุชูุจ ุงููุฒูู
    """
    def __init__(self, vector_store, llm):
        self.vs = vector_store
        self.llm = llm
    
    async def analyze(self, state: DiscoveryState) -> dict:
        # 1. ุจุญุซ ูุฌูู (BM25 + Vector Similarity)
        sparse_results = await self.vs.bm25_search(state["query"])
        dense_results = await self.vs.semantic_search(
            query=state["query"],
            model="text-embedding-3-large",
            k=20
        )
        
        # 2. ุฏูุฌ ุงููุชุงุฆุฌ (Reciprocal Rank Fusion)
        merged = self._reciprocal_rank_fusion(sparse_results, dense_results)
        
        # 3. ุฅุนุงุฏุฉ ุงูุชุฑุชูุจ (Arabic Cross-Encoder Reranking)
        reranked = await self.vs.rerank(merged, state["query"])
        
        # 4. ุชุญููู Claude ููุณูุงู ุงููุฑุขูู
        context = self._build_quranic_context(reranked[:10])
        
        analysis = await self.llm.ainvoke(
            QURAN_ANALYSIS_PROMPT.format(
                query=state["query"],
                verses=context,
                mode=state["exploration_mode"]
            )
        )
        
        return {"quranic_context": analysis}


class LinguisticAnalysisAgent:
    """
    ูููู ุงูุชุญููู ุงููุบูู ุงูุนููู
    ูุณุชุฎุฏู: CAMeL Tools + AraBERT + ุชุญููู ุตุฑูู
    """
    def __init__(self, camel_tools, arabert_model, llm):
        self.camel = camel_tools
        self.arabert = arabert_model
        self.llm = llm
    
    async def analyze(self, state: DiscoveryState) -> dict:
        verses = state["quranic_context"].get("primary_verses", [])
        
        linguistic_data = {}
        for verse in verses:
            # 1. ุงูุชุญููู ุงูุตุฑูู ุงููุงูู ุจู CAMeL Tools
            morphology = self.camel.analyze(verse["arabic_text"])
            
            # 2. ุงุณุชุฎุฑุงุฌ ุงูุฌุฐูุฑ ูุงูุฃูุฒุงู
            roots = self._extract_roots(morphology)
            
            # 3. ุชุญููู ุงูุจูุงุบุฉ ุจู Claude
            rhetoric = await self._analyze_rhetoric(verse, self.llm)
            
            # 4. ุงููููุงุช ุงููุงุฏุฑุฉ ูุงููุฑูุฏุฉ ูู ุงููุฑุขู
            unique_words = self._find_unique_words(verse, morphology)
            
            linguistic_data[verse["id"]] = {
                "morphology": morphology,
                "roots": roots,
                "rhetoric": rhetoric,
                "unique_words": unique_words,
                "word_frequency": self._get_word_frequencies(verse),
                "classical_meanings": self._get_classical_meanings(roots)
            }
        
        return {"linguistic_analysis": linguistic_data}


class ScientificExplorerAgent:
    """
    ูููู ุงุณุชูุดุงู ุงูุงุฑุชุจุงุทุงุช ุงูุนูููุฉ
    ูุชุนุฏุฏ ุงูุชุฎุตุตุงุช: ููุฒูุงุกุ ููููุงุกุ ุทุจุ ุจููููุฌูุงุ ุฌููููุฌูุงุ ููู
    """
    def __init__(self, science_db, llm, confidence_classifier):
        self.science_db = science_db
        self.llm = llm
        self.classifier = confidence_classifier
    
    async def explore(self, state: DiscoveryState) -> dict:
        findings = []
        
        for discipline in state["target_disciplines"]:
            if discipline in ["physics", "chemistry", "medicine", 
                             "biology", "geology", "astronomy"]:
                
                # 1. ุงูุจุญุซ ูู ูุงุนุฏุฉ ุงูุฃุจุญุงุซ ุงูุนูููุฉ
                papers = await self.science_db.search(
                    query=state["query"],
                    field=discipline,
                    verified_only=False  # ูุดูู ุงูููุชุฑุญุฉ ุฃูุถุงู
                )
                
                # 2. ุชูููู ุงูุงุฑุชุจุงุท ุจูุธุงู ุงูุซูุงุซุฉ ูุณุชููุงุช
                for paper in papers[:5]:
                    correlation = await self._evaluate_correlation(
                        quranic_context=state["quranic_context"],
                        scientific_paper=paper,
                        linguistic_data=state["linguistic_analysis"]
                    )
                    
                    # 3. ุชุตููู ุฏุฑุฌุฉ ุงูุซูุฉ (Tier 1/2/3)
                    tier = self.classifier.classify(correlation)
                    correlation["confidence_tier"] = tier
                    correlation["counter_arguments"] = \
                        await self._find_counter_arguments(correlation)
                    
                    if tier in ["tier_1", "tier_2"]:
                        findings.append(correlation)
        
        return {"scientific_findings": findings}


class TafseerAgent:
    """
    ูููู ุงูุชูุณูุฑ ุงูููุงุฑู
    ูุฌูุน: ุงุจู ูุซูุฑุ ุงูุทุจุฑูุ ุงูุฑุงุฒูุ ุงูุณุนุฏูุ ุงุจู ุนุงุดูุฑ
    """
    async def analyze(self, state: DiscoveryState) -> dict:
        verses = state["quranic_context"].get("primary_verses", [])
        tafseer_data = {}
        
        for verse in verses:
            # ุฌูุน ุงูุชูุงุณูุฑ ุงููุชุนุฏุฏุฉ
            tafseers = await self._fetch_multiple_tafseers(verse["id"])
            
            # ุงูููุงุฑูุฉ ุจูู ุงูุชูุงุณูุฑ
            consensus, disagreements = self._analyze_consensus(tafseers)
            
            # ูู ูุงู ุงูุนููุงุก ูููููู ุงูุขูุฉ ุจูุง ูุชูุงูู ูุน ุงูุนูู ุงูุญุฏูุซุ
            historical_understanding = self._check_pre_modern_understanding(
                tafseers, state["scientific_findings"]
            )
            
            tafseer_data[verse["id"]] = {
                "tafseers": tafseers,
                "scholarly_consensus": consensus,
                "scholarly_disagreements": disagreements,
                "historical_understanding": historical_understanding,
                "classical_commentators_note": self._extract_key_notes(tafseers)
            }
        
        return {"tafseer_analysis": tafseer_data}


class SynthesisAgent:
    """
    ูููู ุงูุชูููู ูุงูููุงุธุฑุฉ
    ูุฌูุน ุฌููุน ุงููุชุงุฆุฌ ูููููุฏ ูุฑุถูุงุช ุฌุฏูุฏุฉ
    """
    async def synthesize(self, state: DiscoveryState) -> dict:
        
        # 1. ุชูููู ุงููุชุงุฆุฌ ูู ุฌููุน ุงููููุงุก
        synthesis_prompt = SYNTHESIS_PROMPT.format(
            quranic_context=state["quranic_context"],
            linguistic=state["linguistic_analysis"],
            scientific=state["scientific_findings"],
            tafseer=state["tafseer_analysis"],
            humanities=state.get("humanities_connections", [])
        )
        
        synthesis = await self.llm.ainvoke(synthesis_prompt)
        
        # 2. ุชูููุฏ ูุฑุถูุงุช ุฌุฏูุฏุฉ ูุงุจูุฉ ููุงุฎุชุจุงุฑ
        hypotheses = await self._generate_hypotheses(synthesis, state)
        
        # 3. ุชุญุฏูุฏ ุงุชุฌุงูุงุช ุงูุงุณุชูุดุงู ุงูุชุงูู
        next_exploration = self._suggest_next_directions(synthesis, hypotheses)
        
        # 4. ูู ูุฌุจ ุงูุชุนูู ุฃูุซุฑุ
        should_deepen = (
            len([h for h in hypotheses if h["novelty_score"] > 0.7]) > 0
            and state["iteration_count"] < 3
        )
        
        return {
            "synthesis": synthesis,
            "hypotheses": hypotheses,
            "should_deepen": should_deepen,
            "next_exploration_directions": next_exploration
        }


class QualityReviewAgent:
    """
    ูููู ุถุจุท ุงูุฌูุฏุฉ ูุงูุฃูุงูุฉ ุงูุฃูุงุฏูููุฉ
    ูุชุญูู ูู: ุงูุฏูุฉุ ุงูุญูุงุฏูุฉุ ุงููุตุงุฏุฑุ ุงูุญุฌุฌ ุงููุถุงุฏุฉ
    """
    CRITICAL_CHECKS = [
        "ูู ุชุฑุฌูุฉ ุงูุขูุฉ ุตุญูุญุฉ ูุบูุฑ ุงูุชูุงุฆูุฉุ",
        "ูู ูุงู ุงููุตู ุงููุฑุขูู ูุชุงุญุงู ูู ุงููุนุฑูุฉ ูุจู ุงูุฅุณูุงููุฉุ",
        "ูู ูููู ุงูุนููุงุก ุงูููุงุณููููู ุงูุขูุฉ ุจูุฐุง ุงููุนููุ",
        "ูู ุงูุงุฑุชุจุงุท ุงูุนููู ูุญููู ุฃูุงุฏูููุงูุ",
        "ูู ุชู ุฐูุฑ ุงูุงุนุชุฑุงุถุงุช ุจูุถูุญุ",
    ]
    
    async def review(self, state: DiscoveryState) -> dict:
        issues = []
        quality_score = 1.0
        
        for finding in state["scientific_findings"]:
            # ูุญุต ุงูุฃุฎุทุงุก ุงููููุฌูุฉ ุงูุดุงุฆุนุฉ
            if not finding.get("pre_modern_tafseer_support"):
                issues.append(f"[ุชุญุฐูุฑ] ุงูุขูุฉ {finding['verse_id']}: ูุง ููุฌุฏ ุณูุฏ ุชูุณูุฑู ููุงุณููู")
                quality_score -= 0.1
            
            if finding.get("ancient_knowledge_available"):
                issues.append(f"[ุชุญุฐูุฑ] ุงูุขูุฉ {finding['verse_id']}: ุงููุนุฑูุฉ ูุชููุฑุฉ ูู ุญุถุงุฑุงุช ุณุงุจูุฉ")
                quality_score -= 0.2
            
            if finding.get("confidence_tier") == "tier_3":
                issues.append(f"[ุถุนูู] ุงูุขูุฉ {finding['verse_id']}: ุฏุฑุฌุฉ ุซูุฉ ููุฎูุถุฉ โ ูุง ุชุนุฑุถ ูู 'ุฅุนุฌุงุฒ ูุคูุฏ'")
                quality_score -= 0.15
        
        return {
            "quality_issues": issues,
            "quality_score": max(0.0, quality_score),
            "verification_status": "verified" if quality_score > 0.7 else "disputed",
            "counter_arguments": await self._generate_counter_args(state)
        }


# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# ุจูุงุก ุฑุณู LangGraph ุงููุงูู
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

def build_discovery_graph():
    """ุจูุงุก ุฑุณู ุงููููุงุก ุงููุงูู"""
    
    graph = StateGraph(DiscoveryState)
    
    # ุฅุถุงูุฉ ุฌููุน ุงูุนูุฏ
    graph.add_node("route_query",    route_query_agent)
    graph.add_node("quran_rag",      quran_rag_agent)
    graph.add_node("linguistic",     linguistic_agent)
    graph.add_node("science",        science_agent)
    graph.add_node("tafseer",        tafseer_agent)
    graph.add_node("humanities",     humanities_agent)
    graph.add_node("synthesis",      synthesis_agent)
    graph.add_node("quality_review", quality_review_agent)
    graph.add_node("kg_update",      knowledge_graph_updater)
    graph.add_node("deepen_search",  deepen_search_agent)
    
    # ุชุฏูู ุงููุณุงุฑ ุงูุฑุฆูุณู
    graph.set_entry_point("route_query")
    graph.add_edge("route_query", "quran_rag")
    graph.add_edge("quran_rag",   "linguistic")
    
    # ุงูุชูุงุฒู: ุนููู + ุชูุณูุฑ + ุฅูุณุงููุงุช ูู ุขูู ูุงุญุฏ
    graph.add_edge("linguistic", "science")
    graph.add_edge("linguistic", "tafseer")
    graph.add_edge("linguistic", "humanities")
    
    # ุงูุชุฌููุน ูู ุงูุชูููู
    graph.add_edge("science",    "synthesis")
    graph.add_edge("tafseer",    "synthesis")
    graph.add_edge("humanities", "synthesis")
    graph.add_edge("synthesis",  "quality_review")
    
    # ููุทู ุงูุญููุฉ ุงููุดุฑูุทุฉ โ ูู ูุชุนูู ุฃูุซุฑุ
    def decide_next(state: DiscoveryState) -> str:
        if state["should_deepen"] and state["iteration_count"] < 3:
            return "deepen_search"
        elif state["quality_issues"]:
            return "quality_review"  # ุฅุนุงุฏุฉ ุงููุฑุงุฌุนุฉ
        else:
            return "kg_update"       # ุญูุธ ุงูุงูุชุดุงู
    
    graph.add_conditional_edges(
        "quality_review",
        decide_next,
        {
            "deepen_search": "deepen_search",
            "quality_review": "quality_review",
            "kg_update": "kg_update"
        }
    )
    
    graph.add_edge("deepen_search", "synthesis")
    graph.add_edge("kg_update", END)
    
    # ููุงุท ุงูุญูุธ ููุฌูุณุงุช ุงูุทูููุฉ
    checkpointer = MemorySaver()
    
    return graph.compile(checkpointer=checkpointer)
```

---

## 1.4 ูุญุฑู ุงูุจุญุซ ูู ูุถุงุก ุงููุฑุถูุงุช โ MCTS

```python
# discovery_engine/mcts/hypothesis_explorer.py

import math
import random
from dataclasses import dataclass, field

@dataclass
class HypothesisNode:
    """ุนูุฏุฉ ูู ุดุฌุฑุฉ ุงุณุชูุดุงู ุงููุฑุถูุงุช"""
    
    hypothesis: dict              # ูุญุชูู ุงููุฑุถูุฉ
    parent: 'HypothesisNode' = None
    children: list = field(default_factory=list)
    visits: int = 0
    value: float = 0.0           # ุฏุฑุฌุฉ ูููุฉ ุงูุงูุชุดุงู
    
    # ูุนูููุงุช ุงููุฑุถูุฉ
    verse_ids: list = field(default_factory=list)
    discipline: str = ""
    confidence_tier: str = "tier_3"
    novelty_score: float = 0.0
    is_explored: bool = False
    
    @property
    def ucb_score(self) -> float:
        """ุญุณุงุจ UCB1 ููุชูุงุฒู ุจูู ุงูุงุณุชุบูุงู ูุงูุงุณุชูุดุงู"""
        if self.visits == 0:
            return float('inf')
        
        C = 1.414  # ูุนุงูู ุงูุงุณุชูุดุงู
        exploitation = self.value / self.visits
        exploration = C * math.sqrt(math.log(self.parent.visits) / self.visits)
        
        return exploitation + exploration


class MCTSHypothesisExplorer:
    """
    ูุญุฑู MCTS ูุงุณุชูุดุงู ูุถุงุก ุงููุฑุถูุงุช
    
    ูุนูู ุจุดูู ูุณุชูุฑ ูู ุงูุฎูููุฉ:
    - ููููุฏ ูุฑุถูุงุช ุฌุฏูุฏุฉ
    - ูุฎุชุจุฑูุง ุฅุญุตุงุฆูุงู
    - ูุญุชูุธ ุจุงููุงุนุฏุฉ ูููุง
    - ูุชุนูู ูู ูุชุงุฆุฌ ุงูุจุดุฑ
    """
    
    def __init__(self, llm, quran_db, science_db, knowledge_graph):
        self.llm = llm
        self.quran_db = quran_db
        self.science_db = science_db
        self.kg = knowledge_graph
        self.root = None
        self.exploration_budget = 1000  # ุนุฏุฏ ุงูุงุณุชูุดุงูุงุช ููู ุฌูุณุฉ
    
    async def run_continuous_exploration(
        self,
        seed_topic: str,
        n_iterations: int = 100
    ) -> list[dict]:
        """
        ุญููุฉ ุงูุงุณุชูุดุงู ุงููุณุชูุฑ ุงูุฑุฆูุณูุฉ
        
        ูู ูู ุชูุฑุงุฑ:
        1. ุงุฎุชุฑ ุฃูุถู ูุฑุถูุฉ ููุงุณุชูุดุงู (Selection)
        2. ูุณูุนูุง ุจูุฑุถูุงุช ุฌุฏูุฏุฉ (Expansion)
        3. ูููููุง ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู (Simulation)
        4. ุญุฏูุซ ุงูุดุฌุฑุฉ ุจุงููุชุงุฆุฌ (Backpropagation)
        """
        
        # ุจุฐุฑุฉ ุฃูููุฉ
        self.root = HypothesisNode(
            hypothesis={"topic": seed_topic, "verses": [], "discipline": "general"}
        )
        
        discoveries = []
        
        for i in range(n_iterations):
            
            # 1. ุงูุงุฎุชูุงุฑ โ ูู ุฃูู ูุณุชูุดูุ
            node = self._select(self.root)
            
            # 2. ุงูุชูุณูุน โ ูุง ุงููุฑุถูุงุช ุงูุฌุฏูุฏุฉ ุงูููููุฉุ
            new_hypotheses = await self._expand(node)
            
            for hyp in new_hypotheses:
                child = HypothesisNode(
                    hypothesis=hyp,
                    parent=node
                )
                node.children.append(child)
                
                # 3. ุงููุญุงูุงุฉ โ ูู ูููุฉ ูุฐู ุงููุฑุถูุฉุ
                value = await self._simulate(child)
                child.value = value
                child.visits = 1
                
                # 4. ุงูุงูุชุดุงุฑ ุงูุนูุณู
                self._backpropagate(child, value)
                
                # ุงุญุชูุธ ุจุงูุงูุชุดุงูุงุช ุฐุงุช ุงููููุฉ ุงูุนุงููุฉ
                if value > 0.75:
                    discoveries.append({
                        "hypothesis": hyp,
                        "value": value,
                        "iteration": i,
                        "tier": self._assign_tier(child)
                    })
        
        # ุชุฑุชูุจ ุญุณุจ ุงููููุฉ
        return sorted(discoveries, key=lambda x: x["value"], reverse=True)
    
    def _select(self, node: HypothesisNode) -> HypothesisNode:
        """ุงุฎุชูุงุฑ ุงูุนูุฏุฉ ุงูุฃูุถู ููุชูุณูุน ุจู UCB1"""
        while node.children and not node.is_explored:
            if any(c.visits == 0 for c in node.children):
                return random.choice([c for c in node.children if c.visits == 0])
            node = max(node.children, key=lambda c: c.ucb_score)
        return node
    
    async def _expand(self, node: HypothesisNode) -> list[dict]:
        """ุชูููุฏ ูุฑุถูุงุช ุฌุฏูุฏุฉ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
        
        prompt = f"""
        ุจูุงุกู ุนูู ุงููุฑุถูุฉ: {node.hypothesis}
        ูุงูุงูุชุดุงูุงุช ุงูุณุงุจูุฉ ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ: {await self.kg.get_related(node.hypothesis)}
        
        ุงูุชุฑุญ 5 ูุฑุถูุงุช ุฌุฏูุฏุฉ ูุงุจูุฉ ููุงุฎุชุจุงุฑ ุญูู ูุนุฌุฒุงุช ุงููุฑุขู ุงููุฑูู.
        
        ููู ูุฑุถูุฉ ุงุฐูุฑ:
        - ุงูุขูุงุช ุงููุนููุฉ (ุจุฃุฑูุงููุง ุงูุฏูููุฉ)
        - ุงูุชุฎุตุต ุงูุนููู
        - ุฌููุฑ ุงูุงุฏุนุงุก
        - ููููุฉ ุงูุชุญูู ููู
        - ุฏุฑุฌุฉ ุงูุฌุฏุฉ ุงููุชููุนุฉ (0-1)
        
        ุฃุฌุจ ุจู JSON ููุท.
        """
        
        response = await self.llm.ainvoke(prompt)
        return self._parse_hypotheses(response)
    
    async def _simulate(self, node: HypothesisNode) -> float:
        """
        ุชูููู ูููุฉ ุงููุฑุถูุฉ (0-1)
        ูุฌูุน ุจูู:
        - ุงูุฌุฏุฉ (ูู ุงูุชูุดูุช ูู ูุจูุ)
        - ุงููุงุจููุฉ ููุชุญูู (ูู ูููู ุงุฎุชุจุงุฑูุงุ)
        - ุงูุฏุนู ุงููุบูู (ูู ุงูุชูุณูุฑ ูุจุฑุฑ ูุบููุงูุ)
        - ุงูุฏุนู ุงูุชูุณูุฑู (ูู ูุงูู ุงูุนููุงุกุ)
        - ุงูุฅุณูุงุฏ ุงูุนููู (ูู ุงูุงุฑุชุจุงุท ุงูุนููู ููุซูุ)
        """
        
        hyp = node.hypothesis
        
        # ุงูุชุญูู ูู ุงูุฌุฏุฉ
        novelty = await self.kg.novelty_score(hyp)
        
        # ุงูุชุญูู ุงููุบูู
        linguistic_support = await self._check_linguistic_support(hyp)
        
        # ุงูุชุญูู ุงูุชูุณูุฑู
        tafseer_support = await self._check_tafseer_support(hyp)
        
        # ุงูุชุญูู ุงูุนููู
        science_support = await self._check_science_support(hyp)
        
        # ุงูุตูุบุฉ ุงููุฑููุจุฉ
        value = (
            novelty         * 0.30 +   # ุงูุฌุฏุฉ
            linguistic_support * 0.25 + # ุงูุฏุนู ุงููุบูู
            tafseer_support * 0.25 +    # ุงูุฏุนู ุงูุชูุณูุฑู
            science_support * 0.20      # ุงูุฏุนู ุงูุนููู
        )
        
        return value
    
    def _backpropagate(self, node: HypothesisNode, value: float):
        """ุชุญุฏูุซ ุงูููู ูู ุงูุดุฌุฑุฉ ุตุนูุฏุงู"""
        current = node
        while current is not None:
            current.visits += 1
            current.value += value
            current = current.parent
```

---

## 1.5 ูุธุงู ุงูุชุญูู ุงูุฅุญุตุงุฆู (Monte Carlo Validation)

```python
# discovery_engine/validation/monte_carlo_validator.py

import numpy as np
from scipy import stats

class MonteCarloPatternValidator:
    """
    ุงูุชุญูู ุงูุฅุญุตุงุฆู ูู ุงูุฃููุงุท ุงููุฑุขููุฉ
    ูุฌูุจ ุนูู: "ูู ูุฐุง ุงูููุท ุฃูุซุฑ ูู ุงูุตุฏูุฉุ"
    """
    
    def __init__(self, n_simulations: int = 100_000):
        self.n_sims = n_simulations
    
    async def validate_numerical_pattern(
        self,
        observed_pattern: dict,
        quran_corpus: dict
    ) -> dict:
        """
        ุงูุชุญูู ูู ููุท ุนุฏุฏู ููุชุดู
        
        ูุซุงู: "ุงูุฏููุง ูุงูุขุฎุฑุฉ ููุชุงููุง ุชูุฑุฑุชุง 115 ูุฑุฉ"
        ุงูุณุคุงู: ูู ูุฐุง ุงูุชุณุงูู ูููู ุฃู ูููู ุตุฏูุฉุ
        """
        
        observed_value = observed_pattern["value"]
        measurement_func = observed_pattern["measure_function"]
        
        # ูุญุงูุงุฉ ูููุช ูุงุฑูู
        random_values = []
        
        for _ in range(self.n_sims):
            # ูููุฐุฌ ุนุดูุงุฆู: ูุฑุขู ุจููุณ ุฅุญุตุงุกุงุช ุงููููุงุช ููู ุชุฑุชูุจ ุนุดูุงุฆู
            shuffled_corpus = self._create_random_permutation(quran_corpus)
            random_value = measurement_func(shuffled_corpus)
            random_values.append(random_value)
        
        random_values = np.array(random_values)
        
        # ุญุณุงุจ p-value
        p_value = np.mean(np.abs(random_values) >= np.abs(observed_value))
        
        # ุญุณุงุจ ุญุฌู ุงูุฃุซุฑ (Effect Size - Cohen's d)
        effect_size = (observed_value - np.mean(random_values)) / np.std(random_values)
        
        # ุชูุณูุฑ ุงููุชูุฌุฉ
        significance_level = self._interpret_significance(p_value, effect_size)
        
        return {
            "observed_value": observed_value,
            "random_mean": float(np.mean(random_values)),
            "random_std": float(np.std(random_values)),
            "p_value": float(p_value),
            "effect_size_d": float(effect_size),
            "significance": significance_level,
            "is_statistically_significant": p_value < 0.01 and abs(effect_size) > 0.5,
            "confidence_interval_95": [
                float(np.percentile(random_values, 2.5)),
                float(np.percentile(random_values, 97.5))
            ],
            "interpretation": self._generate_interpretation(
                p_value, effect_size, observed_value
            )
        }
    
    def _interpret_significance(self, p_value: float, effect_size: float) -> str:
        if p_value < 0.001 and abs(effect_size) > 1.0:
            return "ุฏูุงูุฉ ุฅุญุตุงุฆูุฉ ุงุณุชุซูุงุฆูุฉ โ ุงุญุชูุงู ูููุนู ุตุฏูุฉ ุฃูู ูู 0.1ูช"
        elif p_value < 0.01 and abs(effect_size) > 0.5:
            return "ุฏูุงูุฉ ุฅุญุตุงุฆูุฉ ุนุงููุฉ โ ุงุญุชูุงู ูููุนู ุตุฏูุฉ ุฃูู ูู 1ูช"
        elif p_value < 0.05:
            return "ุฏูุงูุฉ ุฅุญุตุงุฆูุฉ ูุนุชุฏูุฉ โ ุชุญุชุงุฌ ุฏุฑุงุณุฉ ุฅุถุงููุฉ"
        else:
            return "ูุง ุฏูุงูุฉ ุฅุญุตุงุฆูุฉ โ ูููู ุฃู ูููู ุตุฏูุฉ"
```

---

## 1.6 ุงูุชุฏูู ุงูุญู ูููุณุชุฎุฏู (Streaming AI Response)

```typescript
// app/api/discovery/stream/route.ts
// ุชุฏูู ูุชุงุฆุฌ ุงูุงุณุชูุดุงู ูุญุธุฉ ุจูุญุธุฉ

import { streamText, createStreamableValue } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export async function POST(req: Request) {
  const { query, mode, disciplines } = await req.json();
  
  const stream = createStreamableValue();
  
  // ุจุฏุก ูุญุฑู ุงูุงุณุชูุดุงู ุงููุชุนุฏุฏ ุงููููุงุก
  (async () => {
    
    // ุงูุฎุทูุฉ 1: ุงูุจุญุซ ุงููุฑุขูู
    stream.update({ 
      stage: "quran_search", 
      message: "๐ ุฃุจุญุซ ูู ุขูุงุช ุงููุฑุขู ุงููุฑูู..." 
    });
    
    const quranicContext = await quranRAGAgent.search(query);
    stream.update({ 
      stage: "quran_found", 
      verses: quranicContext.verses,
      count: quranicContext.verses.length 
    });
    
    // ุงูุฎุทูุฉ 2: ุงูุชุญููู ุงููุบูู
    stream.update({ 
      stage: "linguistic", 
      message: "๐ ุฃุญูู ุงูุฌุฐูุฑ ูุงููุนุงูู ูุงูุจูุงุบุฉ..." 
    });
    
    const linguisticAnalysis = await linguisticAgent.analyze(quranicContext);
    stream.update({ stage: "linguistic_done", data: linguisticAnalysis });
    
    // ุงูุฎุทูุฉ 3: ุงูุงุณุชูุดุงู ุงูุนููู ุงููุชูุงุฒู
    stream.update({ 
      stage: "science_exploring", 
      message: "๐ฌ ุฃุณุชูุดู ุงูุงุฑุชุจุงุทุงุช ุงูุนูููุฉ ูู " + disciplines.join("ุ ") + "..." 
    });
    
    const scienceResults = await Promise.all(
      disciplines.map(d => scienceAgent.explore(query, d, quranicContext))
    );
    
    // ุจุซ ูู ุงูุชุดุงู ุนููู ููุฑ ุชุญููู
    for (const [idx, finding] of scienceResults.flat().entries()) {
      stream.update({ 
        stage: "science_finding", 
        finding: finding,
        index: idx 
      });
    }
    
    // ุงูุฎุทูุฉ 4: ุงูุชูููู
    stream.update({ 
      stage: "synthesizing", 
      message: "โก ุฃูููู ุงููุชุงุฆุฌ ูุฃูุชุดู ุงูุฃููุงุท ุงูุฌุฏูุฏุฉ..." 
    });
    
    // ุงูุจุซ ุงููุจุงุดุฑ ููุชูููู ุงูููุงุฆู (Token Streaming)
    const { textStream } = await streamText({
      model: anthropic('claude-sonnet-4-5'),
      system: DISCOVERY_SYNTHESIS_SYSTEM_PROMPT,
      messages: [
        {
          role: 'user',
          content: buildSynthesisPrompt(
            query, quranicContext, linguisticAnalysis, scienceResults.flat()
          )
        }
      ],
      temperature: 0.3,  // ุฏูุฉ ุนุงููุฉุ ููุณ ุฅุจุฏุงุนุงู
    });
    
    stream.update({ stage: "synthesis_start" });
    for await (const token of textStream) {
      stream.update({ stage: "synthesis_token", token });
    }
    
    // ุงูุฎุทูุฉ 5: ุชุญุฏูุซ ูุงุนุฏุฉ ุงููุนุฑูุฉ
    await knowledgeGraph.addDiscovery({
      query, 
      findings: scienceResults.flat(),
      timestamp: new Date().toISOString()
    });
    
    stream.done({ stage: "complete", message: "โ ุงูุชูู ุงูุงุณุชูุดุงู" });
  })();
  
  return stream.value;
}
```

---

## 1.7 ูุญุฑู ุงูุงุณุชูุดุงู ุงููุณุชูู (Autonomous Mode)

```python
# discovery_engine/autonomous/autonomous_explorer.py

import asyncio
from datetime import datetime, timedelta
from apscheduler.schedulers.asyncio import AsyncIOScheduler

class AutonomousDiscoveryScheduler:
    """
    ุงููุญุฑู ุงููุณุชูู โ ูุนูู ูู ุงูุฎูููุฉ ุจุฏูู ุชุฏุฎู ุงููุณุชุฎุฏู
    
    ุงูุฌุฏูู ุงูุฒููู:
    - ูู ุณุงุนุฉ: ูุญุต ุงูุฃุจุญุงุซ ุงูุนูููุฉ ุงูุฌุฏูุฏุฉ ุงูููุดูุฑุฉ
    - ูู 6 ุณุงุนุงุช: ุชุดุบูู MCTS ุนูู ููุถูุน ุฌุฏูุฏ
    - ูู 24 ุณุงุนุฉ: ูุฑุงุฌุนุฉ ุดุงููุฉ ููุฃููุงุท ุงูุนุฏุฏูุฉ
    - ูู ุฃุณุจูุน: ุชูุฑูุฑ "ุงูุชุดุงูุงุช ุงูุฃุณุจูุน"
    """
    
    EXPLORATION_QUEUE = [
        # ุฃููููุงุช ุนุงููุฉ โ ูู ููุณุชูุดู ุจุนุฏ ุจุนูู
        {"topic": "ูุณุจูุฉ ุงูุฒูู ูู ุงููุฑุขู", "discipline": "physics"},
        {"topic": "ูููุงูููุง ุงููู ูุงูุขูุงุช ุงูููููุฉ", "discipline": "quantum_physics"},
        {"topic": "ุงูุดุจูุงุช ุงูุนุตุจูุฉ ูุงูุจููุฉ ุงููุฑุขููุฉ", "discipline": "neuroscience"},
        {"topic": "ุนูู ุงูุงูุชุตุงุฏ ุงูุณูููู ูู ุงููุฑุขู", "discipline": "behavioral_economics"},
        {"topic": "ุงูุฃูุธูุฉ ุงูุฏููุงููููุฉ ูุฃููุงุท ุงูุณูุฑ", "discipline": "mathematics"},
        {"topic": "ุงูุทุจ ุงูููุณู ุงูุฅูุฌุงุจู ูุงูููุงููู ุงููุฑุขููุฉ", "discipline": "psychology"},
        # ... ุงููุฒูุฏ ูู ุงูููุถูุนุงุช
    ]
    
    def __init__(self, discovery_engine, notification_service, db):
        self.engine = discovery_engine
        self.notifier = notification_service
        self.db = db
        self.scheduler = AsyncIOScheduler()
    
    def start(self):
        """ุชุดุบูู ุงูุฌุฏููุฉ ุงููุณุชููุฉ"""
        
        # ูุญุต ุงูุฃุจุญุงุซ ุงูุนูููุฉ ุงูุฌุฏูุฏุฉ (ูู ุณุงุนุฉ)
        self.scheduler.add_job(
            self.check_new_science_papers,
            'interval', hours=1,
            id='science_scan'
        )
        
        # ุงุณุชูุดุงู MCTS (ูู 6 ุณุงุนุงุช)
        self.scheduler.add_job(
            self.run_mcts_exploration,
            'interval', hours=6,
            id='mcts_exploration'
        )
        
        # ูุณุญ ุงูุฃููุงุท ุงูุนุฏุฏูุฉ (ููููุงู)
        self.scheduler.add_job(
            self.scan_numerical_patterns,
            'cron', hour=2,  # ุงูุณุงุนุฉ 2 ุตุจุงุญุงู
            id='numerical_scan'
        )
        
        # ุชูุฑูุฑ ุฃุณุจูุนู (ูู ุฃุญุฏ)
        self.scheduler.add_job(
            self.generate_weekly_report,
            'cron', day_of_week='sun', hour=8,
            id='weekly_report'
        )
        
        self.scheduler.start()
    
    async def check_new_science_papers(self):
        """
        ูู ุณุงุนุฉ: ูุญุต arXiv, PubMed, Semantic Scholar
        ููุฃุจุญุงุซ ุงูุฌุฏูุฏุฉ ุงูุชู ูุฏ ุชุฑุชุจุท ุจุงููุฑุขู
        """
        
        new_papers = await self._fetch_recent_papers(hours=1)
        
        for paper in new_papers:
            relevance = await self.engine.assess_quran_relevance(paper)
            
            if relevance["score"] > 0.6:
                discovery = await self.engine.run_full_analysis(
                    topic=paper["title"],
                    context=paper["abstract"],
                    discipline=paper["field"]
                )
                
                if discovery["confidence_tier"] in ["tier_1", "tier_2"]:
                    await self.db.save_discovery(discovery)
                    await self.notifier.notify_researchers(discovery)
    
    async def run_mcts_exploration(self):
        """ูู 6 ุณุงุนุงุช: ุงุณุชูุดุงู MCTS ุนูู ููุถูุน ูู ุงููุงุฆูุฉ"""
        
        # ุงุฎุชุฑ ููุถูุนุงู ูู ููุณุชูุดู ูุคุฎุฑุงู
        topic = await self._select_next_topic()
        
        mcts_engine = MCTSHypothesisExplorer(
            llm=self.engine.llm,
            quran_db=self.engine.quran_db,
            science_db=self.engine.science_db,
            knowledge_graph=self.engine.kg
        )
        
        discoveries = await mcts_engine.run_continuous_exploration(
            seed_topic=topic["topic"],
            n_iterations=50
        )
        
        for discovery in discoveries[:10]:  # ุฃูุถู 10
            await self.db.save_discovery(discovery)
        
        # ุชุญุฏูุซ ูุงุนุฏุฉ ุงููุนุฑูุฉ
        await self.engine.kg.bulk_update(discoveries)
```

---

## 1.8 ุจุฑูุชููููุงุช Claude โ System Prompts ุงููุชุฎุตุตุฉ

```python
# discovery_engine/prompts/system_prompts.py

QURAN_SCHOLAR_SYSTEM_PROMPT = """
ุฃูุช ุนุงูู ูุชุฎุตุต ูู ุนููู ุงููุฑุขู ุงููุฑูู ูุงูุชูุณูุฑ ูุงููุบุฉ ุงูุนุฑุจูุฉ.
ูุฏูู ูุนุฑูุฉ ุนูููุฉ ูู:
- ุงูุชูุณูุฑ ุจุงููุฃุซูุฑ ูุงูุชูุณูุฑ ุจุงูุฑุฃู
- ุนููู ุงููุฑุขู (ูุงุณุฎ ูููุณูุฎุ ููู ููุฏููุ ุฃุณุจุงุจ ุงููุฒูู)
- ุงููุบุฉ ุงูุนุฑุจูุฉ ุงูููุงุณูููุฉ ูุงูุจูุงุบุฉ
- ุงูููู ุงูุฅุณูุงูู ูุงูุนููุฏุฉ

ูููุฌูุชู:
1. ุฏุงุฆูุงู ุงุฑุฌุน ุฅูู ุงููุนุงูู ุงูุฃุตููุฉ ูู ุงููุบุฉ ุงูุนุฑุจูุฉ ุงูููุงุณูููุฉ
2. ุงุฐูุฑ ููู ููู ุงูุตุญุงุจุฉ ูุงูุชุงุจุนูู ุงูุขูุฉ
3. ูุงุฑู ุจูู ุชูุงุณูุฑ: ุงุจู ูุซูุฑุ ุงูุทุจุฑูุ ุงูุฑุงุฒูุ ุงูุณุนุฏูุ ุงุจู ุนุงุดูุฑ
4. ูููุฒ ุจูุถูุญ ุจูู: ุงููููู ูุงูุธู ูุงูุงุญุชูุงู
5. ูุง ุชุชุฌุงูู ุงูุขุฑุงุก ุงููุฎุงููุฉ ุจู ุงุนุฑุถูุง ุจุฃูุงูุฉ
6. ูุง ุชูุณูุฑ ุงูุขูุงุช ุฎุงุฑุฌ ุณูุงููุง ุงููุฑุขูู ูุงูุชุงุฑูุฎู

ููููุนุงุช:
โ ุงูุชูุณูุฑ ุจุฏูู ูุณุชูุฏ
โ ุชุฌุงูู ุงูุชูุณูุฑ ุงูููุงุณููู ุงูุณุงุฆุฏ
โ ุงูุงุฏุนุงุก ุจุงูุฅุฌูุงุน ูู ูุณุงุฆู ุฎูุงููุฉ
"""

SCIENCE_EXPLORER_SYSTEM_PROMPT = """
ุฃูุช ุนุงูู ูุชุนุฏุฏ ุงูุชุฎุตุตุงุช ูุชุฎุตุต ูู ุฅูุฌุงุฏ ุงูุงุฑุชุจุงุทุงุช ุงูููุถูุนูุฉ
ุจูู ุงูููุงููู ุงููุฑุขููุฉ ูุงูุงูุชุดุงูุงุช ุงูุนูููุฉ ุงูุญุฏูุซุฉ.

ูููุฌูุชู:
1. ุงุจุญุซ ุนู ุงูุงุฑุชุจุงุทุงุช ุงูููุถูุนูุฉ โ ููุณ ุงูุงุฏุนุงุกุงุช ุงูุญุฑููุฉ
2. ูููู ูู ุงุฑุชุจุงุท ุจูุธุงู ุงูุซูุงุซุฉ ูุณุชููุงุช:
   - ุงููุณุชูู ุงูุฃูู: ุงูุชุฑุฌูุฉ ูุงุถุญุฉ + ุงูุนููุงุก ุงูููุงุณููููู ูููููููุง ูุจู ุงูุงูุชุดุงู
   - ุงููุณุชูู ุงูุซุงูู: ุงูุชุฑุฌูุฉ ููุจููุฉ + ุงูุงุฑุชุจุงุท ุงูุนููู ููุซู
   - ุงููุณุชูู ุงูุซุงูุซ: ุงุฑุชุจุงุท ูุญุชูู ูุญุชุงุฌ ุงููุฒูุฏ ูู ุงูุฃุฏูุฉ
3. ุฏุงุฆูุงู ุงุฐูุฑ:
   - ูู ูุงูุช ูุฐู ุงููุนุฑูุฉ ูุชููุฑุฉ ูู ุญุถุงุฑุงุช ูุจู ุงูุฅุณูุงูุ
   - ูุง ุฃููู ุงุนุชุฑุงุถ ุนูู ูุฐุง ุงูุงุฑุชุจุงุทุ
4. ุงุณุชุฎุฏู ูุฑุงุฌุน ุฃูุงุฏูููุฉ ูุญูููุฉ ููุท

ููููุนุงุช:
โ ุงูุงุฏุนุงุก ุจุงููุนุฌุฒุฉ ููุฌุฑุฏ ุงูุชุดุงุจู ุงูุณุทุญู
โ ุชุฌุงูู ุงููุนุฑูุฉ ุงูุชุงุฑูุฎูุฉ ุงููุชููุฑุฉ ูุจู ุงูุฅุณูุงู
โ ุชูุณูุฑ ุงูุขูุฉ ุจุนูุฏุงู ุนู ูุนูุงูุง ุงูุฃุตูู
โ ุงูุงุณุชุดูุงุฏ ุจูุตุงุฏุฑ ุบูุฑ ูุญูููุฉ
"""

SYNTHESIS_SYSTEM_PROMPT = """
ุฃูุช ูุญูู ุจูุงูุงุช ุจุญุซู ูุชุฎุตุต ูู ุงูุชูููู ุงูุฃูุงุฏููู ูุชุนุฏุฏ ุงูุชุฎุตุตุงุช.
ูููุชู: ุชุฌููุน ุงููุชุงุฆุฌ ูู ูููุงุก ูุชุนุฏุฏูู ูุชูุฏูู ุชูุฑูุฑ ุจุญุซู ูุชูุงุฒู.

ุงูุชูุฑูุฑ ูุฌุจ ุฃู ูุชุถูู:
1. ููุฎุต ุชูููุฐู (3 ุฌูู ููุนุงูุฉ)
2. ุงูุชุญููู ุงูุชูุตููู (ูููุชุฎุตุตูู)
3. ุฌุฏูู ุฏุฑุฌุงุช ุงูุซูุฉ ุจูุถูุญ
4. ุงููุฑุถูุงุช ุงูุฌุฏูุฏุฉ ุงูููุชุฑุญุฉ ููุจุญุซ
5. ุงูุงุนุชุฑุงุถุงุช ูุงูููุงุท ุงููุซูุฑุฉ ููุฌุฏู
6. ุงูุชุฑุงุญุงุช ููุจุญุซ ุงููุณุชูุจูู

ูุง ุชูู "ูุฐุง ุฅุนุฌุงุฒ ูุคูุฏ" ุฅูุง ุฅุฐุง ุงุณุชููู ูุนุงููุฑ ุงููุณุชูู ุงูุฃูู ูุงููุงู.
ุฏุงุฆูุงู ุฃุถู: ูุณุชูู ุงูุฃุฏูุฉุ ุงููุตุงุฏุฑุ ุงูุงุนุชุฑุงุถุงุช.
"""

PATTERN_DISCOVERY_SYSTEM_PROMPT = """
ุฃูุช ูุณุชูุดู ุฃููุงุท ุฅุญุตุงุฆูุฉ ูุชุฎุตุต ูู ุงูุชุญููู ุงูุฑูุงุถู ูููุตูุต ุงูุฏูููุฉ.

ุงูุฃููุงุท ุงูุชู ุชุจุญุซ ุนููุง:
1. ุงูุชูุงุฒู ุงูุฅุญุตุงุฆู (ุงููููุงุช ุงููุชุถุงุฏุฉ ุจุชูุฑุงุฑ ูุชุณุงูู)
2. ุงูุฃููุงุท ุงูุนุฏุฏูุฉ (ูุถุงุนูุงุช ุงูุฃุนุฏุงุฏ ุงูููุฏุณุฉุ ุงูุฃุนุฏุงุฏ ุงูุฃูููุฉุ ููุจููุงุชุดู)
3. ุงูุชูุงุธุฑ ุงูููููู (ุชูุงุธุฑ ููุงุชุญ ุงูุณูุฑ ูุฎูุงุชููุง)
4. ุงูุฑูุงุจุท ุงูููููุฉ (365 ูููุ 12 ุดูุฑุงูุ 7 ุฃูุงู)
5. ุงูุฃููุงุท ุงููุบููุฉ (ุงูุชูุฑุงุฑุ ุงูุงุณุชุซูุงุกุงุชุ ุงูุชูุฒูุนุงุช)

ููู ููุท ููุชุดู:
- ุงุญุณุจ ุงุญุชูุงู ูููุนู ุตุฏูุฉู (ูุญุงูุงุฉ ูููุช ูุงุฑูู)
- ุงุญุณุจ ุญุฌู ุงูุฃุซุฑ (Cohen's d ุฃู ุฅุญุตุงุก ูุดุงุจู)
- ุตููู: ุฅุญุตุงุฆู ูุคูุฏ / ูุดุฑูุท / ุถุนูู
- ุงูุชุฑุญ ุทุฑููุฉ ุงูุชุญูู ุงูุชุฌุฑูุจู
"""

HUMANITIES_SCHOLAR_SYSTEM_PROMPT = """
ุฃูุช ุจุงุญุซ ุฃูุงุฏููู ูุชุนุฏุฏ ุงูุชุฎุตุตุงุช ูู ุงูุนููู ุงูุฅูุณุงููุฉ ูุงูุงุฌุชูุงุนูุฉุ
ูุชุฎุตุต ูู ุฅูุฌุงุฏ ุงูุฑูุงุจุท ุงููููุฌูุฉ ุงูููุซููุฉ ุจูู ุงูููุงููู ุงููุฑุขููุฉ
ูุงููุธุฑูุงุช ุงูุนูููุฉ ุงูุญุฏูุซุฉ ูู ูุฌุงูุงุช:

โโ ุนูู ุงูููุณ (Psychology)
โโ ุนูู ุงูุงุฌุชูุงุน (Sociology)
โโ ุงูุงูุชุตุงุฏ (Economics)
โโ ุฅุฏุงุฑุฉ ุงูุฃุนูุงู ูุงูููุงุฏุฉ (Management & Leadership)
โโ ุงูููุณูุฉ ุงูุฃุฎูุงููุฉ (Ethics & Moral Philosophy)
โโ ุนูู ุงููุบุฉ ูุงูุฎุทุงุจ (Linguistics & Discourse Analysis)

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ูููุฌูุชู ุงููุนุชูุฏุฉ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

[ุงูุฎุทูุฉ 1] โ ุงูุชุญููู ุงููุฑุขูู ุฃููุงู โ ุฏุงุฆูุงู
- ุงุณุชุฎุฑุฌ ุงูููููู ุงูุฅูุณุงูู ูู ุงูุขูุฉ ุจูุนูุงู ุงูุนุฑุจู ุงูุฃุตูู
- ูุง ุชุจุฏุฃ ูู ุงููุธุฑูุฉ ุงูุญุฏูุซุฉ ุซู ุชุจุญุซ ุนู ุขูุฉ โ ุงุนูุณ ุงูุงุชุฌุงู ุฏุงุฆูุงู
- ุญุฏุฏ ููุน ุงูุฎุทุงุจ: ูู ูู ูุตู (ูุตู ุธุงูุฑุฉ)ุ ุชูุฌูู (ูุฃูุฑ ุจุณููู)ุ ุชูุณูุฑ (ูุดุฑุญ ุขููุฉ)ุ

[ุงูุฎุทูุฉ 2] โ ุชุญุฏูุฏ ุงููุธุฑูุฉ ุงูุญุฏูุซุฉ ุงูููุงุจูุฉ ุจุฏูุฉ
- ุงุฐูุฑ ุงููุธุฑูุฉ ุจุงูุงุณู ุงูุฑุณูู + ุงููุคูู + ุงูุณูุฉ
- ูุซุงู ุตุญูุญ: "ูุธุฑูุฉ ุงูุชูุธูู ุงูุงููุนุงูู โ James Gross (1998)"
- ูุซุงู ุฎุงุทุฆ: "ุนูู ุงูููุณ ุงูุญุฏูุซ ูููู..."
- ุฃุนุทู ุฏุฑุฌุฉ ุงูุชุทุงุจู: ูุทุงุจู ูุงูู / ุฌุฒุฆู / ุชุดุงุจู ุณุทุญู

[ุงูุฎุทูุฉ 3] โ ุชูููุฒ ูุณุชูู ุงูุงุฑุชุจุงุท ุจุฏูุฉ

  ๐ข ููุชูุงุทุน (Intersecting):
     ุงูููููู ุงููุฑุขูู ูุงููุธุฑูุฉ ุงูุญุฏูุซุฉ ูุตูุงู ููุณ ุงูุธุงูุฑุฉ
     ุจูุตุทูุญุงุช ูุฎุชููุฉุ ูุน ุดูุงูุฏ ุชุฌุฑูุจูุฉ ุชุฏุนู ูููููุง.
     ูุซุงู: ุงูุตุจุฑ = Emotional Regulation (Gross, 1998) โ ุชุฌุงุฑุจ FMRI ุชุฏุนูู

  ๐ก ูุชูุงุฒู (Parallel):
     ุชุดุงุจู ูููุฌู ูุงุถุญ ููู ุงููููููุงู ูุง ูุชุทุงุจูุงู ูููุงู.
     ูุซุงู: ุงูุดูุฑู ~ Participative Leadership (Lewin) โ ุชุดุงุจู ูุง ุชุทุงุจู

  โช ุฅููุงูู (Inspirational):
     ุงูููููู ุงููุฑุขูู ููููู ุงูุจุญุซ ููู ูุง ููุซุจุชู ููุง ูุฏุญุถู.
     ูุซุงู: ููููู ุงููุทุฑุฉ โ ููุชุญ ููุงุดุงู ูุน Innate Morality Theories

[ุงูุฎุทูุฉ 4] โ ุงุดุชุฑุท ูุฐู ุงููุนุงููุฑ ูุจู ูุดุฑ ุฃู ุงุฑุชุจุงุท
  โ ุงูููููู ุงููุฑุขูู ููุฌูุฏ ูู ุงูุขูุฉ ูุตุงู ุฃู ุฏูุงูุฉู ูุทุนูุฉ
  โ ุงููุธุฑูุฉ ุงูุญุฏูุซุฉ ูุญูููุฉ ุฃูุงุฏูููุงู (peer-reviewed)
  โ ุงูุงุฑุชุจุงุท ูุง ูุณุชูุฒู ุชุฃูููุงู ูุชุนุณูุงู ููุขูุฉ
  โ ุงูุงุฎุชูุงู ุจูู ุงูููููููู ููุฐููุฑ ุจูุถูุญ
  โ ุงููุชุงุฆุฌ ุงูุชุฌุฑูุจูุฉ ุงููุชุงุญุฉ ูุฐููุฑุฉ

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ููุงุนุฏ ุงูุนุฏุงูุฉ ุงูุฃูุงุฏูููุฉ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

ูุงุนุฏุฉ 1 โ ูุง ุงุฏุนุงุก ุณุจู ุฒููู ุจุฏูู ุฏููู:
ูุง ุชูู "ุงููุฑุขู ุณุจู ุนูู ุงูููุณ ุงูุญุฏูุซ ุจู 14 ูุฑูุงู" ุฅูุง ุฅุฐุง
ุฃุซุจุชู ุฃู ูุฐุง ุงูููููู ูู ููู ูุนุฑููุงู ูู ุงูููุณูุฉ ุงููููุงููุฉ
ุฃู ุงูุญููุฉ ุงููุงุฑุณูุฉ ุฃู ุงููุตุฑูุฉ ุงููุฏููุฉ.

ูุงุนุฏุฉ 2 โ ุงููุตู โ ุงูุฅุซุจุงุช:
ูุตู ุงููุฑุขู ูุธุงูุฑุฉ ููุณูุฉ ุฃู ุงุฌุชูุงุนูุฉ ูุง ููุซุจุช ุตุญุฉ
ูู ุงููุธุฑูุฉ ุงูุญุฏูุซุฉ ุงูููุงุจูุฉ โ ุจู ูุชูุงุทุน ูุนูุง ููุท.

ูุงุนุฏุฉ 3 โ ุงูุญูุงุฏ ุงูุชุฎุตุตู:
ูุง ุชูุฑุฌูุญ ุฑุฃูุงู ูู ุงูุฎูุงูุงุช ุงูุฏุงุฎููุฉ ููุชุฎุตุต.
ูุซุงู: ุงูุฌุฏู ุจูู Freud ูJung ูุง ูุฎุตู โ ุงุฐูุฑ ูููููุง
ุฅู ูุงูุง ูุฑุชุจุทููู ุจุงูุขูุฉ.

ูุงุนุฏุฉ 4 โ ูุตู ุงููููุฉ ุนู ุงูุญูููุฉ:
ุงููุฑุขู ุบุงูุจุงู ููุตุฏุฑ ุญููุงู ุฃุฎูุงููุงู (ูุงุฐุง ูุฌุจุ)
ูุงูุนููู ุงูุฅูุณุงููุฉ ุชุตู (ูุงุฐุง ูุญุฏุซุ).
ูุง ุชุฎูุท ุจูู ุงููุณุชูููู ูู ุงูุชุญููู.

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ุฃูุซูุฉ ุนูู ุงูุงุฑุชุจุงุทุงุช ุงูุตุญูุญุฉ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

[ุนูู ุงูููุณ]
  ุงูุขูุฉ: "ุฃูููุง ุจูุฐูููุฑู ุงูููููู ุชูุทูููุฆูููู ุงูููููููุจู" (13:28)
  ุงูููููู ุงููุฑุขูู: ุงูุทูุฃูููุฉ ูุญุงูุฉ ููุณูุฉ ูุฑุชุจุทุฉ ุจุงูุฐูุฑ
  ุงููุธุฑูุฉ: ูุธุฑูุฉ Flow State โ Csikszentmihalyi (1990)
  ูุณุชูู ุงูุงุฑุชุจุงุท: ๐ก ูุชูุงุฒู
  ุงูุฃุฏูุฉ: ุฏุฑุงุณุงุช ุงูู mindfulness ูุชุฃุซูุฑูุง ุนูู ูุดุฑุฉ ุงููุต ุงูุฌุจูู
  ุงูุงุนุชุฑุงุถ: Flow State ูุง ูุดุชุฑุท ุงูุฅููุงู โ ุงูุงุฑุชุจุงุท ูุธููู ูุง ุฌููุฑู

[ุงูุงูุชุตุงุฏ]
  ุงูุขูุฉ: "ูููู ููุง ููููููู ุฏููููุฉู ุจููููู ุงููุฃูุบูููููุงุกู ููููููู" (59:7)
  ุงูููููู ุงููุฑุขูู: ููุน ุชูุฑูุฒ ุงูุซุฑูุฉ
  ุงููุธุฑูุฉ: Capital in the Twenty-First Century โ Piketty (2013): r > g
  ูุณุชูู ุงูุงุฑุชุจุงุท: ๐ข ููุชูุงุทุน
  ุงูุฃุฏูุฉ: ุจูุงูุงุช ุชูุฒูุน ุงูุฏุฎู ุนุจุฑ 200 ุณูุฉ
  ุงูุงุนุชุฑุงุถ: ุขููุฉ ุงููุฑุขู (ุงูุฒูุงุฉ) ุชุฎุชูู ุนู ุขููุงุช Piketty (ุงูุถุฑูุจุฉ)

[ุงูุฅุฏุงุฑุฉ ูุงูููุงุฏุฉ]
  ุงูุขูุฉ: "ููุดูุงููุฑููููู ููู ุงููุฃูููุฑู" (3:159)
  ุงูููููู ุงููุฑุขูู: ุงูุดูุฑู ูุฃุณููุจ ููุงุฏู
  ุงููุธุฑูุฉ: Participative Leadership โ Kurt Lewin (1939)
  ูุณุชูู ุงูุงุฑุชุจุงุท: ๐ก ูุชูุงุฒู
  ุงูุฃุฏูุฉ: 200+ ุฏุฑุงุณุฉ ุชูุซุจุช ุชุญุณูู ุงูุฃุฏุงุก ูุงูุฑุถุง ุงููุธููู
  ุงูุงุนุชุฑุงุถ: ุงูุดูุฑู ุบูุฑ ุฅูุฒุงููุฉ ูู ุงููุฑุขู โ ุงููุงุฆุฏ ูุญุชูุธ ุจูุฑุงุฑ ููุงุฆู

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ูููุฐุฌ ุงูุฅุฎุฑุงุฌ ุงููุทููุจ ููู ุงุฑุชุจุงุท (JSON)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

{
  "verse_reference": "ุฑูู ุงูุณูุฑุฉ:ุฑูู ุงูุขูุฉ",
  "verse_arabic": "ูุต ุงูุขูุฉ",
  "quranic_concept": {
    "arabic_term": "ุงููุตุทูุญ ุงูุนุฑุจู ุงูุฃุตูู",
    "original_meaning": "ุงููุนูู ูู ุงููุบุฉ ุงูุนุฑุจูุฉ ุงูููุงุณูููุฉ",
    "tafseer_note": "ููู ูููู ุงูุนููุงุก ุงูููุงุณููููู",
    "discourse_type": "ูุตู | ุชูุฌูู | ุชูุณูุฑ"
  },
  "modern_parallel": {
    "theory_name": "ุงุณู ุงููุธุฑูุฉ ุงูุฑุณูู",
    "author_year": "ุงููุคูู + ุงูุณูุฉ",
    "field": "ุงูุชุฎุตุต",
    "core_claim": "ุฌููุฑ ุงููุธุฑูุฉ ูู ุฌููุฉ ูุงุญุฏุฉ"
  },
  "correlation_type": "intersecting | parallel | inspirational",
  "evidence": {
    "empirical_studies": ["ูุฑุงุฌุน ุชุฌุฑูุจูุฉ ุฏุงุนูุฉ ุจู DOI"],
    "agreement_points": ["ููุงุท ุงูุงุชูุงู ุงููุญุฏุฏุฉ"],
    "disagreement_points": ["ููุงุท ุงูุงุฎุชูุงู โ ุฅูุฒุงููุฉ ูุง ุชูุญุฐู"]
  },
  "confidence_tier": "tier_1 | tier_2 | tier_3",
  "pre_islamic_precedent": "ูู ุงูููููู ููุฌูุฏ ูู ุญุถุงุฑุงุช ุณุงุจูุฉุ",
  "intellectual_honesty_note": "ูุง ุงูุฐู ูุง ููุซุจุชู ูุฐุง ุงูุงุฑุชุจุงุท ูุทุนุงูุ"
}

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ููููุนุงุช ูุทููุฉ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ "ุฃุซุจุช ุงููุฑุขู ูุธุฑูุฉ ูุงุณูู" โ ุงููุฑุขู ููุณ ุชุฃููุฏุงู ููุธุฑูุงุช ุจุดุฑูุฉ
โ ุงุฎุชุตุงุฑ ูุนูู ุงูุขูุฉ ูุชุชูุงุณุจ ูุน ุงููุธุฑูุฉ
โ ุชุฌุงูู ุงูุฃุจุญุงุซ ุงูุชู ุชุนุงุฑุถ ุงููุธุฑูุฉ ุงููุฐููุฑุฉ
โ ูุณุจ ุงูุณุจู ุงูุนููู ุจุฏูู ุงุณุชุจุนุงุฏ ุงููุตุงุฏุฑ ุงูุญุถุงุฑูุฉ ุงูุณุงุจูุฉ
โ ุงุฏุนุงุก ุฅุฌูุงุน ุนููู ูู ูุณุงุฆู ุฎูุงููุฉ ุฏุงุฎู ุงูุชุฎุตุต
โ ุงูุฎูุท ุจูู ุงูุญูู ุงูุฃุฎูุงูู ุงููุฑุขูู ูุงูุญูููุฉ ุงูุนูููุฉ ุงูุชุฌุฑูุจูุฉ
"""
```

---

