#!/usr/bin/env python3
"""ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙØ§Ø³ÙŠØ± Ù…Ù† Ù…Ù„ÙØ§Øª JSON Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª PostgreSQL.

ÙŠÙ‚Ø±Ø£ Ù…Ù„ÙØ§Øª JSON Ù…Ù† data/tafseers/ ÙˆÙŠØ¯Ø®Ù„Ù‡Ø§ ÙÙŠ Ø¬Ø¯Ø§ÙˆÙ„:
  - tafseer_books (Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹)
  - tafseers (Ø§Ù„Ù†ØµÙˆØµ Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø¢ÙŠØ§Øª)

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    python scripts/load_tafseers_to_db.py
    python scripts/load_tafseers_to_db.py --db-url postgresql://user:pass@host/db
    python scripts/load_tafseers_to_db.py --dry-run  # Ø¹Ø±Ø¶ Ø¨Ø¯ÙˆÙ† ØªÙ†ÙÙŠØ°
"""

import argparse
import asyncio
import json
import os
import sys
from pathlib import Path

import asyncpg

PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data" / "tafseers"

# ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©
TAFSEER_BOOKS = [
    {
        "slug": "ibn-katheer",
        "name_ar": "ØªÙØ³ÙŠØ± Ø§Ø¨Ù† ÙƒØ«ÙŠØ±",
        "name_en": "Tafsir Ibn Kathir",
        "author_ar": "Ø¥Ø³Ù…Ø§Ø¹ÙŠÙ„ Ø¨Ù† ÙƒØ«ÙŠØ±",
        "author_death_year": 774,
        "methodology": "Ø£Ø«Ø±ÙŠ",
        "priority_order": 1,
    },
    {
        "slug": "al-tabari",
        "name_ar": "Ø¬Ø§Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù† (Ø§Ù„Ø·Ø¨Ø±ÙŠ)",
        "name_en": "Jami al-Bayan (al-Tabari)",
        "author_ar": "Ø§Ø¨Ù† Ø¬Ø±ÙŠØ± Ø§Ù„Ø·Ø¨Ø±ÙŠ",
        "author_death_year": 310,
        "methodology": "Ø£Ø«Ø±ÙŠ",
        "priority_order": 2,
    },
    {
        "slug": "al-shaarawy",
        "name_ar": "ØªÙØ³ÙŠØ± Ø§Ù„Ø´Ø¹Ø±Ø§ÙˆÙŠ â€” Ø®ÙˆØ§Ø·Ø± Ø­ÙˆÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…",
        "name_en": "Tafsir al-Shaarawy",
        "author_ar": "Ù…Ø­Ù…Ø¯ Ù…ØªÙˆÙ„Ù‰ Ø§Ù„Ø´Ø¹Ø±Ø§ÙˆÙŠ",
        "author_death_year": 1998,
        "methodology": "Ø¨ÙŠØ§Ù†ÙŠ-Ù„ØºÙˆÙŠ-Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ",
        "priority_order": 3,
    },
    {
        "slug": "al-razi",
        "name_ar": "Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØºÙŠØ¨ (Ø§Ù„Ø±Ø§Ø²ÙŠ)",
        "name_en": "Mafatih al-Ghayb (al-Razi)",
        "author_ar": "ÙØ®Ø± Ø§Ù„Ø¯ÙŠÙ† Ø§Ù„Ø±Ø§Ø²ÙŠ",
        "author_death_year": 606,
        "methodology": "Ø¹Ù‚Ù„ÙŠ",
        "priority_order": 4,
    },
    {
        "slug": "al-saadi",
        "name_ar": "ØªÙØ³ÙŠØ± Ø§Ù„Ø³Ø¹Ø¯ÙŠ",
        "name_en": "Tafsir al-Saadi",
        "author_ar": "Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø³Ø¹Ø¯ÙŠ",
        "author_death_year": 1376,
        "methodology": "ØªÙŠØ³ÙŠØ±ÙŠ",
        "priority_order": 5,
    },
    {
        "slug": "ibn-ashour",
        "name_ar": "Ø§Ù„ØªØ­Ø±ÙŠØ± ÙˆØ§Ù„ØªÙ†ÙˆÙŠØ±",
        "name_en": "al-Tahrir wal-Tanwir",
        "author_ar": "Ø§Ø¨Ù† Ø¹Ø§Ø´ÙˆØ±",
        "author_death_year": 1393,
        "methodology": "Ø¥ØµÙ„Ø§Ø­ÙŠ",
        "priority_order": 6,
    },
    {
        "slug": "al-qurtubi",
        "name_ar": "Ø§Ù„Ø¬Ø§Ù…Ø¹ Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø±Ø¢Ù†",
        "name_en": "al-Jami li-Ahkam al-Quran",
        "author_ar": "Ø§Ù„Ù‚Ø±Ø·Ø¨ÙŠ",
        "author_death_year": 671,
        "methodology": "ÙÙ‚Ù‡ÙŠ",
        "priority_order": 7,
    },
]


async def ensure_tafseer_books(conn: asyncpg.Connection) -> dict[str, int]:
    """Ø£Ø¯Ø®Ù„ ÙƒØªØ¨ Ø§Ù„ØªÙØ³ÙŠØ± ÙˆØ£Ø¹Ø¯ mapping slug â†’ id."""
    slug_to_id = {}

    for book in TAFSEER_BOOKS:
        row = await conn.fetchrow(
            "SELECT id FROM tafseer_books WHERE slug = $1", book["slug"]
        )
        if row:
            slug_to_id[book["slug"]] = row["id"]
        else:
            book_id = await conn.fetchval(
                """
                INSERT INTO tafseer_books
                    (slug, name_ar, name_en, author_ar,
                     author_death_year, methodology, priority_order)
                VALUES ($1, $2, $3, $4, $5, $6, $7)
                RETURNING id
                """,
                book["slug"],
                book["name_ar"],
                book["name_en"],
                book["author_ar"],
                book["author_death_year"],
                book["methodology"],
                book["priority_order"],
            )
            slug_to_id[book["slug"]] = book_id
            print(f"  âœ… Ø£ÙØ¶ÙŠÙ: {book['name_ar']} (id={book_id})")

    return slug_to_id


async def get_verse_id_map(conn: asyncpg.Connection) -> dict[str, int]:
    """Ø¨Ù†Ø§Ø¡ mapping Ù…Ù† verse_key â†’ verse_id."""
    rows = await conn.fetch(
        "SELECT id, surah_number, verse_number FROM verses"
    )
    return {
        f"{r['surah_number']}:{r['verse_number']}": r["id"]
        for r in rows
    }


async def load_tafseer_file(
    conn: asyncpg.Connection,
    json_path: Path,
    book_id: int,
    verse_map: dict[str, int],
    dry_run: bool = False,
) -> dict:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØªÙØ³ÙŠØ± JSON ÙˆØ§Ø­Ø¯ Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""
    data = json.loads(json_path.read_text(encoding="utf-8"))
    stats = {"loaded": 0, "skipped": 0, "missing_verse": 0}

    surahs = data.get("surahs", {})

    for surah_num, entries in surahs.items():
        for entry in entries:
            verse_key = entry.get("verse_key", "")
            text = entry.get("text", "").strip()

            if not text:
                stats["skipped"] += 1
                continue

            verse_id = verse_map.get(verse_key)
            if not verse_id:
                stats["missing_verse"] += 1
                continue

            if not dry_run:
                await conn.execute(
                    """
                    INSERT INTO tafseers (verse_id, book_id, text)
                    VALUES ($1, $2, $3)
                    ON CONFLICT (verse_id, book_id)
                    DO UPDATE SET text = EXCLUDED.text
                    """,
                    verse_id,
                    book_id,
                    text,
                )

            stats["loaded"] += 1

    return stats


async def main():
    parser = argparse.ArgumentParser(
        description="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙØ§Ø³ÙŠØ± Ù…Ù† JSON Ø¥Ù„Ù‰ PostgreSQL"
    )
    parser.add_argument(
        "--db-url",
        default=os.environ.get(
            "DATABASE_URL",
            "postgresql://quran_user:changeme@localhost:5432/quran_miracles",
        ),
        help="Ø±Ø§Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Ø¹Ø±Ø¶ Ù…Ø§ Ø³ÙŠØªÙ… Ø¨Ø¯ÙˆÙ† ØªÙ†ÙÙŠØ°",
    )
    args = parser.parse_args()

    db_url = args.db_url.replace("postgresql+asyncpg://", "postgresql://")

    if not DATA_DIR.exists():
        print(f"âŒ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªÙØ§Ø³ÙŠØ± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {DATA_DIR}")
        print("   Ø´ØºÙ‘Ù„ Ø£ÙˆÙ„Ø§Ù‹: python scripts/fetch_tafseers.py")
        sys.exit(1)

    json_files = list(DATA_DIR.glob("*.json"))
    if not json_files:
        print(f"âŒ Ù„Ø§ Ù…Ù„ÙØ§Øª JSON ÙÙŠ {DATA_DIR}")
        print("   Ø´ØºÙ‘Ù„ Ø£ÙˆÙ„Ø§Ù‹: python scripts/fetch_tafseers.py")
        sys.exit(1)

    print(f"ğŸ“‚ ÙˆÙØ¬Ø¯ {len(json_files)} Ù…Ù„Ù ØªÙØ³ÙŠØ±")
    if args.dry_run:
        print("ğŸ” ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙ†Ø© â€” Ù„Ù† ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    conn = await asyncpg.connect(db_url)

    try:
        # 1. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒØªØ¨ Ø§Ù„ØªÙØ³ÙŠØ±
        print("\nğŸ“š Ø¥Ø¹Ø¯Ø§Ø¯ ÙƒØªØ¨ Ø§Ù„ØªÙØ³ÙŠØ±...")
        slug_to_id = await ensure_tafseer_books(conn)
        print(f"   {len(slug_to_id)} ÙƒØªØ§Ø¨ Ø¬Ø§Ù‡Ø²")

        # 2. Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¢ÙŠØ§Øª
        print("\nğŸ—ºï¸ Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¢ÙŠØ§Øª...")
        verse_map = await get_verse_id_map(conn)
        print(f"   {len(verse_map)} Ø¢ÙŠØ© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

        if not verse_map:
            print("âŒ Ù„Ø§ Ø¢ÙŠØ§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
            print("   Ø´ØºÙ‘Ù„ Ø£ÙˆÙ„Ø§Ù‹: python backend/scripts/apply_schema.py")
            return

        # 3. ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ù…Ù„Ù
        total_stats = {"loaded": 0, "skipped": 0, "missing_verse": 0}

        for json_path in sorted(json_files):
            # Ø§Ø³ØªØ®Ø±Ø¬ slug Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            slug = json_path.stem.replace("_qurancom", "")

            book_id = slug_to_id.get(slug)
            if not book_id:
                print(f"  âš ï¸ ØªØ®Ø·ÙŠ {json_path.name} â€” Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙƒØªØ§Ø¨ Ø¨Ù€ slug={slug}")
                continue

            print(f"\nğŸ“– ØªØ­Ù…ÙŠÙ„ {json_path.name}...")
            stats = await load_tafseer_file(
                conn, json_path, book_id, verse_map, args.dry_run
            )
            total_stats["loaded"] += stats["loaded"]
            total_stats["skipped"] += stats["skipped"]
            total_stats["missing_verse"] += stats["missing_verse"]
            print(
                f"   âœ… {stats['loaded']} Ø¢ÙŠØ© Ù…Ø­Ù…Ù„Ø©"
                f" | â­ï¸ {stats['skipped']} ÙØ§Ø±ØºØ©"
                f" | âš ï¸ {stats['missing_verse']} Ø¢ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
            )

        print(f"\n{'=' * 50}")
        print(f"ğŸ“Š Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ:")
        print(f"   âœ… {total_stats['loaded']} ØªÙØ³ÙŠØ± Ù…Ø­Ù…Ù‘Ù„")
        print(f"   â­ï¸ {total_stats['skipped']} ÙØ§Ø±Øº")
        print(f"   âš ï¸ {total_stats['missing_verse']} Ø¢ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")

    finally:
        await conn.close()


if __name__ == "__main__":
    asyncio.run(main())
